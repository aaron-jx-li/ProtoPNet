{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fc4916-c7e1-4989-a8d6-7b052156a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import heapq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from receptive_field import compute_rf_prototype\n",
    "from helpers import makedir, find_high_activation_crop\n",
    "import shutil\n",
    "\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from helpers import makedir\n",
    "import model\n",
    "import push\n",
    "import prune\n",
    "import train_and_test as tnt\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "\n",
    "from bounding_box_metrics import bounding_box_overlap\n",
    "from find_nearest import find_k_nearest_patches_to_prototypes, imsave_with_bbox, ImagePatch, ImagePatchInfo\n",
    "\n",
    "from settings import train_dir, test_dir, train_push_dir, train_batch_size, test_batch_size, train_push_batch_size\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, prototype_activation_function, add_on_layers_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a19d46-b3df-4c90-a7c0-81952c193e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppnet = torch.load(r'/scratch/users/jiaxun1218/saved_models/vgg19_10/r1_0.7380.pth')\n",
    "#ppnet_multi = ppnet.cuda()\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2727883c-c8c1-4484-b832-6176d28295b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_push_dir = './stanford_cars/car_data/car_data/train'\n",
    "#test_dir = './stanford_cars/car_data/car_data/test'\n",
    "#train_dir = './stanford_cars/car_data/car_data/train_augmented'\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        train_push_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accd01e8-15ac-4b2d-bddd-c0b2af642e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 8156\n",
       "    Root location: ./stanford_cars/car_data/car_data/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81119f1-fd3c-4566-a23c-3acbf419c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find nearest patches\n",
      "1.0\n",
      "batch 0\n",
      "batch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfind_k_nearest_patches_to_prototypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_push_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# pytorch dataloader (must be unnormalized in [0,1])\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mppnet_multi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# pytorch network with prototype_vectors\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mpreprocess_input_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# normalize if needed\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfull_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# save all the images\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mroot_dir_for_saving_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./R1_cars/005_densenet161_prototypes/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mprototype_activation_function_in_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ProtoPNet/find_nearest.py:111\u001b[0m, in \u001b[0;36mfind_k_nearest_patches_to_prototypes\u001b[0;34m(dataloader, prototype_network_parallel, k, preprocess_input_function, full_save, root_dir_for_saving_images, log, prototype_activation_function_in_numpy, heatmap_ratio)\u001b[0m\n\u001b[1;32m    107\u001b[0m closest_patch_distance_to_prototype_j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mamin(distance_map[j])\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_save:\n\u001b[1;32m    110\u001b[0m     closest_patch_indices_in_distance_map_j \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munravel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdistance_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    113\u001b[0m     closest_patch_indices_in_distance_map_j \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m closest_patch_indices_in_distance_map_j\n\u001b[1;32m    114\u001b[0m     closest_patch_indices_in_img \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    115\u001b[0m         compute_rf_prototype(search_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    116\u001b[0m                              closest_patch_indices_in_distance_map_j,\n\u001b[1;32m    117\u001b[0m                              protoL_rf_info)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "find_k_nearest_patches_to_prototypes(train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "                                         ppnet_multi, # pytorch network with prototype_vectors\n",
    "                                         k=1,\n",
    "                                         preprocess_input_function=None, # normalize if needed\n",
    "                                         full_save=True, # save all the images\n",
    "                                         root_dir_for_saving_images='./icml_figures/R1_vgg_bird/',\n",
    "                                         log=print,\n",
    "                                         prototype_activation_function_in_numpy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb454d-5792-437b-b48c-abe4a4be41de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
