{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ff05e3-3c85-48df-b176-07acc1d284d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features\n",
    "from densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features\n",
    "from vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\\\n",
    "                         vgg19_features, vgg19_bn_features\n",
    "\n",
    "from receptive_field import compute_proto_layer_rf_info_v2\n",
    "\n",
    "from settings import img_size\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle as pkl\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "from preference_model import construct_PrefNet, paired_cross_entropy_loss, PrefNet\n",
    "\n",
    "# book keeping namings and code\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, \\\n",
    "                     prototype_activation_function, add_on_layers_type, experiment_run\n",
    "\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24e8ec3-9edc-4387-bc86-80c966f94c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_architecture_to_features = {'resnet18': resnet18_features,\n",
    "                                 'resnet34': resnet34_features,\n",
    "                                 'resnet50': resnet50_features,\n",
    "                                 'resnet101': resnet101_features,\n",
    "                                 'resnet152': resnet152_features,\n",
    "                                 'densenet121': densenet121_features,\n",
    "                                 'densenet161': densenet161_features,\n",
    "                                 'densenet169': densenet169_features,\n",
    "                                 'densenet201': densenet201_features,\n",
    "                                 'vgg11': vgg11_features,\n",
    "                                 'vgg11_bn': vgg11_bn_features,\n",
    "                                 'vgg13': vgg13_features,\n",
    "                                 'vgg13_bn': vgg13_bn_features,\n",
    "                                 'vgg16': vgg16_features,\n",
    "                                 'vgg16_bn': vgg16_bn_features,\n",
    "                                 'vgg19': vgg19_features,\n",
    "                                 'vgg19_bn': vgg19_bn_features}\n",
    "\n",
    "\n",
    "class PrefNet(nn.Module):\n",
    "\n",
    "    def __init__(self, img_features, pattern_features, img_size, prototype_shape,\n",
    "                 proto_layer_rf_info, num_classes, init_weights=False,\n",
    "                 prototype_activation_function='log',\n",
    "                 add_on_layers_type='bottleneck', \n",
    "                k = 1):\n",
    "\n",
    "        super(PrefNet, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.prototype_shape = prototype_shape\n",
    "        self.num_prototypes = prototype_shape[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = 1e-4\n",
    "        self.k = k\n",
    "        \n",
    "        # this has to be named features to allow the precise loading\n",
    "        self.img_features = img_features\n",
    "        self.pattern_features = pattern_features\n",
    "        \n",
    "        '''\n",
    "        features_name = str(self.features).upper()\n",
    "        if features_name.startswith('VGG') or features_name.startswith('RES'):\n",
    "            first_add_on_layer_in_channels = \\\n",
    "                [i for i in features.modules() if isinstance(i, nn.Conv2d)][-1].out_channels\n",
    "        elif features_name.startswith('DENSE'):\n",
    "            first_add_on_layer_in_channels = \\\n",
    "                [i for i in features.modules() if isinstance(i, nn.BatchNorm2d)][-1].num_features\n",
    "        else:\n",
    "            raise Exception('other base base_architecture NOT implemented')\n",
    "        '''\n",
    "        \n",
    "        '''    \n",
    "        if add_on_layers_type == 'bottleneck':\n",
    "            add_on_layers = []\n",
    "            current_in_channels = first_add_on_layer_in_channels\n",
    "            while (current_in_channels > self.prototype_shape[1]) or (len(add_on_layers) == 0):\n",
    "                current_out_channels = max(self.prototype_shape[1], (current_in_channels // 2))\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_in_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                add_on_layers.append(nn.ReLU())\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_out_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                if current_out_channels > self.prototype_shape[1]:\n",
    "                    add_on_layers.append(nn.ReLU())\n",
    "                else:\n",
    "                    assert(current_out_channels == self.prototype_shape[1])\n",
    "                    add_on_layers.append(nn.Sigmoid())\n",
    "                current_in_channels = current_in_channels // 2\n",
    "            self.add_on_layers = nn.Sequential(*add_on_layers)\n",
    "        else:\n",
    "            self.add_on_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=first_add_on_layer_in_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "        '''\n",
    "                \n",
    "#         self.prototype_vectors = nn.Parameter(torch.rand(self.prototype_shape),\n",
    "#                                               requires_grad=True)\n",
    "\n",
    "#         # do not make this just a tensor,\n",
    "#         # since it will not be moved automatically to gpu\n",
    "#         self.ones = nn.Parameter(torch.ones(self.prototype_shape),\n",
    "#                                  requires_grad=False)\n",
    "\n",
    "#         self.last_layer = nn.Linear(self.num_prototypes, self.num_classes,\n",
    "#                                     bias=False) # do not use bias\n",
    "    \n",
    "\n",
    "        self.img_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2048, out_channels=512, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.pattern_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2048, out_channels=512, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.final_fc = nn.Sequential(\n",
    "            # change here\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        \n",
    "            )\n",
    "        \n",
    "        #self.fc1 = nn.Linear(6400, 512)\n",
    "        #self.fc2 = nn.Linear(512, 32)\n",
    "        #self.fc3 = nn.Linear(32, 1)\n",
    "        #self.fc1 = nn.Linear(64, 16)\n",
    "        \n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "            \n",
    "    def conv_features(self, x):\n",
    "        '''\n",
    "        the feature input to prototype layer\n",
    "        '''\n",
    "        # Insert k and then img size\n",
    "        x = self.features(x)\n",
    "        #print(\"base features: \", x.shape)\n",
    "        #x = self.add_on_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, p):\n",
    "        \n",
    "        x = self.img_features(x)\n",
    "        x = self.img_conv(x)\n",
    "        \n",
    "        p = self.pattern_features(p)\n",
    "        p = self.pattern_conv(p)\n",
    "        \n",
    "        #out = torch.cat((x, p), dim=1)\n",
    "        out = torch.flatten(p, 1) \n",
    "        out = self.final_fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.img_conv.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        for m in self.pattern_conv.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def construct_PrefNet(base_architecture, pretrained=True, img_size=224,\n",
    "                    prototype_shape=(1000, 128, 1, 1), num_classes=200,\n",
    "                    prototype_activation_function='log',\n",
    "                    add_on_layers_type='bottleneck',\n",
    "                    k = 1):\n",
    "    img_features = base_architecture_to_features[base_architecture](pretrained=pretrained)\n",
    "    pattern_features = base_architecture_to_features[base_architecture](pretrained=pretrained)\n",
    "    layer_filter_sizes, layer_strides, layer_paddings = img_features.conv_info()\n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(img_size=img_size,\n",
    "                                                         layer_filter_sizes=layer_filter_sizes,\n",
    "                                                         layer_strides=layer_strides,\n",
    "                                                         layer_paddings=layer_paddings,\n",
    "                                                         prototype_kernel_size=prototype_shape[2])\n",
    "    return PrefNet(img_features=img_features,\n",
    "                   pattern_features=pattern_features,\n",
    "                 img_size=img_size,\n",
    "                 prototype_shape=prototype_shape,\n",
    "                 proto_layer_rf_info=proto_layer_rf_info,\n",
    "                 num_classes=num_classes,\n",
    "                 init_weights=True,\n",
    "                 prototype_activation_function=prototype_activation_function,\n",
    "                 add_on_layers_type=add_on_layers_type,\n",
    "                 k = k)\n",
    "\n",
    "\n",
    "def paired_cross_entropy_loss(out1, out2, targets):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in range(len(targets)):\n",
    "        \n",
    "        if targets[i] == -1:\n",
    "            p1 = torch.exp(out1[i])/(torch.exp(out1[i]) + torch.exp(out2[i]))\n",
    "            loss = - torch.log(p1)\n",
    "        elif targets[i] == 1:\n",
    "            p2 = torch.exp(out2[i])/(torch.exp(out1[i]) + torch.exp(out2[i]))\n",
    "            loss = - torch.log(p2)\n",
    "\n",
    "        else:\n",
    "            p1 = torch.exp(out1[i])/(torch.exp(out1[i]) + torch.exp(out2[i]))\n",
    "            p2 = torch.exp(out2[i])/(torch.exp(out1[i]) + torch.exp(out2[i]))\n",
    "            loss = - (0.5*torch.log(p1) + 0.5*torch.log(p2))\n",
    "            \n",
    "        total_loss += loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f49dcf9-20fe-47be-8873-4da82e1364f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6085547e-f8ef-4945-9427-99775779a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean,\n",
    "                                 std=std)\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(size=(img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae1b813-0ec8-4636-be71-2626d7d56d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "new_csv_name = \"./human_comparisons/cars.csv\"\n",
    "if os.path.exists(new_csv_name):\n",
    "    new_comp_df = pd.read_csv(new_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda48c53-b535-4834-88b9-e503638225cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comp_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_csv_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./human_comparisons/ratings_processed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m new_comp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcomp_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_id\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m: comp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_id\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m: comp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:]})\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_comp_df))\n\u001b[1;32m      4\u001b[0m new_comp_df\u001b[38;5;241m.\u001b[39mto_csv(new_csv_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comp_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_csv_name = \"./human_comparisons/ratings_processed.csv\"\n",
    "new_comp_df = pd.DataFrame({\"imgid\": comp_df['img_id'][1:], \"pid\": comp_df['p_id'][1:], \"rating\": comp_df['rating'][1:]})\n",
    "print(len(new_comp_df))\n",
    "new_comp_df.to_csv(new_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f90b69-abfd-4646-9de1-f110ca33df2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "new_csv_name = \"./human_comparisons/ratings_processed.csv\"\n",
    "new_comp_df = pd.read_csv(new_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ee9c34-35eb-4481-9357-a3668334b9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32072\n",
      "22292\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "700 rating setup\n",
    "'''\n",
    "split = 0.5\n",
    "df_len = len(new_comp_df)\n",
    "train_set = []\n",
    "test_set = []\n",
    "split_idx = int(df_len*split)\n",
    "for i in range(split_idx):\n",
    "    for j in range(i+1, split_idx):\n",
    "        if new_comp_df.iloc[i]['rating'] > new_comp_df.iloc[j]['rating'] + 0.5:\n",
    "            train_set.append([i, j, -1])\n",
    "        elif new_comp_df.iloc[i]['rating'] + 0.5 < new_comp_df.iloc[j]['rating']:\n",
    "            train_set.append([i, j, 1])\n",
    "            \n",
    "for i in range(split_idx, df_len):\n",
    "    for j in range(i+1, df_len):\n",
    "        if new_comp_df.iloc[i]['rating'] > new_comp_df.iloc[j]['rating'] + 1.5:\n",
    "            test_set.append([i, j, -1])\n",
    "        elif new_comp_df.iloc[i]['rating'] + 1.5 < new_comp_df.iloc[j]['rating']:\n",
    "            test_set.append([i, j, 1])\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d040f9c-e83d-4e22-b6af-9816f91d18b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27210\n",
      "13831\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "300/500 rating setup\n",
    "'''\n",
    "split = 0.7\n",
    "df_len = 300\n",
    "train_set = []\n",
    "test_set = []\n",
    "split_idx = int(df_len)\n",
    "for i in range(split_idx):\n",
    "    for j in range(i+1, split_idx):\n",
    "        if comp_df.iloc[i]['rating'] > comp_df.iloc[j]['rating']:\n",
    "            train_set.append([i, j, -1])\n",
    "        elif comp_df.iloc[i]['rating'] < comp_df.iloc[j]['rating']:\n",
    "            train_set.append([i, j, 1])\n",
    "            \n",
    "for i in range(int(700*split), 700):\n",
    "    for j in range(i+1, 700):\n",
    "        if comp_df.iloc[i]['rating'] > comp_df.iloc[j]['rating']:\n",
    "            test_set.append([i, j, -1])\n",
    "        elif comp_df.iloc[i]['rating'] < comp_df.iloc[j]['rating']:\n",
    "            test_set.append([i, j, 1])\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9735f02f-1df1-44fe-8ceb-2b11b74dbd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "patterns = []\n",
    "#heatmaps = []\n",
    "for i in range(len(new_comp_df)):\n",
    "    #img = './human_comparisons/feedback_images/cars/original_imgs/' + str(int(new_comp_df.iloc[i]['img_id'])) + '_' + str(int(new_comp_df.iloc[i]['p_id'])) + '.png'\n",
    "    #img = plt.imread(img)[:, :, :3]\n",
    "    #img = np.transpose(img, (2, 0, 1))\n",
    "    #images.append(torch.from_numpy(np.array([img])))\n",
    "    pattern = './human_comparisons/feedback_images/cars/patterns/' + str(int(new_comp_df.iloc[i]['img_id'])) + '_' + str(int(new_comp_df.iloc[i]['p_id'])) + '.npy'\n",
    "    pattern = np.load(pattern)\n",
    "    pattern = np.array([pattern, pattern, pattern])\n",
    "    patterns.append(torch.from_numpy(np.array([pattern])))\n",
    "    heatmap = './human_comparisons/feedback_images/cars/heatmaps/' + str(int(new_comp_df.iloc[i]['img_id'])) + '_' + str(int(new_comp_df.iloc[i]['p_id'])) + '.png'\n",
    "    heatmap = plt.imread(heatmap)[:, :, :3]\n",
    "    heatmap = np.transpose(heatmap, (2, 0, 1))\n",
    "    images.append(torch.from_numpy(np.array([heatmap])))\n",
    "#print(len(images))\n",
    "#print(images[10].shape)\n",
    "#print(patterns[10].shape)\n",
    "print(len(images))\n",
    "print(images[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d72c5389-78fc-451b-80cf-b71b84cf8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefnet = construct_PrefNet(\"resnet50\")\n",
    "prefnet.to(device)\n",
    "prefnet.train()\n",
    "\n",
    "for p in prefnet.final_fc.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in prefnet.img_features.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in prefnet.pattern_features.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in prefnet.img_conv.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in prefnet.pattern_conv.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "pref_optimizer = optim.Adam([{'params': prefnet.img_features.parameters(), 'lr': 1e-4, 'weight_decay':1e-4}, {'params': prefnet.pattern_features.parameters(), 'lr': 1e-4, 'weight_decay':1e-4},\n",
    "                             #{'params': prefnet.add_on_layers.parameters(), 'lr': 1e-4}, \n",
    "                             {'params': prefnet.img_conv.parameters(), 'lr': 1e-3, 'weight_decay':1e-3}, {'params': prefnet.pattern_conv.parameters(), 'lr': 1e-3, 'weight_decay':1e-3}, \n",
    "                             {'params': prefnet.final_fc.parameters(), 'lr': 1e-3, 'weight_decay':1e-3}\n",
    "                             #{'params': prefnet.fc1.parameters(), 'lr': 1e-4}, {'params': prefnet.fc2.parameters(), 'lr': 1e-4}, {'params': prefnet.fc3.parameters(), 'lr': 1e-4}\n",
    "                             ])\n",
    "\n",
    "pref_lr_step_size = 1\n",
    "gamma = 0.1\n",
    "pref_lr_scheduler = torch.optim.lr_scheduler.StepLR(pref_optimizer, step_size=pref_lr_step_size, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02701876-96a7-4cbd-85ef-60411844684d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "weight_decay = 1e-5\n",
    "pref_optimizer = optim.Adam([{'params': prefnet.img_features.parameters(), 'lr': lr, 'weight_decay':weight_decay}, {'params': prefnet.pattern_features.parameters(), 'lr': lr, 'weight_decay':weight_decay},\n",
    "                             #{'params': prefnet.add_on_layers.parameters(), 'lr': 1e-4}, \n",
    "                             {'params': prefnet.img_conv.parameters(), 'lr': lr, 'weight_decay':weight_decay}, {'params': prefnet.pattern_conv.parameters(), 'lr': lr, 'weight_decay':weight_decay}, \n",
    "                             {'params': prefnet.final_fc.parameters(), 'lr': lr, 'weight_decay':weight_decay}\n",
    "                             #{'params': prefnet.fc1.parameters(), 'lr': 1e-4}, {'params': prefnet.fc2.parameters(), 'lr': 1e-4}, {'params': prefnet.fc3.parameters(), 'lr': 1e-4}\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03374bd-a7f3-4043-8c5e-c9f07f946f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87195424-557c-45ed-8bd7-a10a30ea5222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4378]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefnet(images[9].cuda(), patterns[9].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7261f4-cfc1-4355-95d5-a3efe9a39da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reward_model(prefnet, test_set, images, patterns, batch_size):\n",
    "    acc = []\n",
    "    error_count = 0\n",
    "    all_idx = np.arange(len(test_set))\n",
    "    for batch_i in tqdm(range(len(test_set)//batch_size + 1)):\n",
    "        prefnet.eval()\n",
    "        \n",
    "        idx = all_idx[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "        \n",
    "        left_imgs = torch.zeros((batch_size, 3, 224, 224))\n",
    "        right_imgs = torch.zeros((batch_size, 3, 224, 224))\n",
    "        left_patterns = torch.zeros((batch_size, 3, 224, 224))\n",
    "        right_patterns = torch.zeros((batch_size, 3, 224, 224))\n",
    "        targets = []\n",
    "        for i in range(len(idx)):\n",
    "            index = idx[i]\n",
    "            left_imgs[i] = images[test_set[index][0]][0]\n",
    "            right_imgs[i] = images[test_set[index][1]][0]\n",
    "            targets.append(test_set[index][2])\n",
    "            left_patterns[i] = patterns[test_set[index][0]][0]\n",
    "            right_patterns[i] = patterns[test_set[index][1]][0]\n",
    "        \n",
    "        targets = torch.tensor(targets).cuda().float()\n",
    "        \n",
    "        out1 = prefnet(left_imgs.cuda().float(), left_patterns.cuda().float())\n",
    "        out2 = prefnet(right_imgs.cuda().float(), right_patterns.cuda().float())\n",
    "\n",
    "        \n",
    "        \n",
    "        for i in range(len(targets)):\n",
    "\n",
    "            if out1[i] > out2[i]:\n",
    "                y_pred = -1\n",
    "\n",
    "            else:\n",
    "                y_pred = 1\n",
    "\n",
    "            \n",
    "            if y_pred == targets[i]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                error_count += 1\n",
    "                acc.append(0)\n",
    "            \n",
    "    return np.mean(acc), error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2198894-4479-4614-99c6-fd55fd7fdac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697/697 [01:09<00:00,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 499 0.8635384891440876 3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save() missing 1 required positional argument: 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(epoch, batch_i, test_acc, test_error_count)\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.85\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./human_comparisons/reward_model_cars_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_acc\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m pref_lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mTypeError\u001b[0m: save() missing 1 required positional argument: 'f'"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    shuffled_idx = np.random.permutation(len(train_set))\n",
    "    for batch_i in range(len(train_set)//batch_size + 1):\n",
    "        prefnet.train()\n",
    "        if batch_i % 100 == 0:\n",
    "            last_100_losses = []\n",
    "            last_100_error_count = 0\n",
    "        idx = shuffled_idx[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "        \n",
    "        left_imgs = torch.zeros((batch_size, 3, 224, 224))\n",
    "        right_imgs = torch.zeros((batch_size, 3, 224, 224))\n",
    "        left_patterns = torch.zeros((batch_size, 3, 224, 224))\n",
    "        right_patterns = torch.zeros((batch_size, 3, 224, 224))\n",
    "        targets = []\n",
    "        for i in range(len(idx)):\n",
    "            index = idx[i]\n",
    "            left_imgs[i] = images[train_set[index][0]][0]\n",
    "            right_imgs[i] = images[train_set[index][1]][0]\n",
    "            targets.append(train_set[index][2])\n",
    "            left_patterns[i] = patterns[train_set[index][0]][0]\n",
    "            right_patterns[i] = patterns[train_set[index][1]][0]\n",
    "        \n",
    "        targets = torch.tensor(targets).cuda().float()\n",
    "        \n",
    "        out1 = prefnet(left_imgs.cuda().float(), left_patterns.cuda().float())\n",
    "        out2 = prefnet(right_imgs.cuda().float(), right_patterns.cuda().float())\n",
    "\n",
    "        \n",
    "        pref_optimizer.zero_grad()   \n",
    "        \n",
    "        for i in range(len(targets)):\n",
    "            if out1[i] > out2[i] and targets[i] == 1:\n",
    "                last_100_error_count += 1\n",
    "\n",
    "            elif out1[i] < out2[i] and targets[i] == -1:\n",
    "                last_100_error_count += 1\n",
    "                \n",
    "        loss = paired_cross_entropy_loss(out1, out2, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        pref_optimizer.step()   \n",
    "        \n",
    "        last_100_losses.append(loss.data.cpu().numpy()[0])\n",
    "        \n",
    "        #if batch_i % 100 == 0:\n",
    "        #    print(epoch, batch_i, np.sum(last_100_losses))\n",
    "        #if batch_i % 100 == 99:\n",
    "        #    print(epoch, batch_i, last_100_error_count)\n",
    "        if batch_i % 500 == 499:\n",
    "            \n",
    "            test_acc, test_error_count = test_reward_model(prefnet, test_set, images, patterns, batch_size)\n",
    "            print(epoch, batch_i, test_acc, test_error_count)\n",
    "            if test_acc > 0.85:\n",
    "                torch.save(prefnet, f'./human_comparisons/reward_model_cars_{test_acc}.pth')\n",
    "    pref_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a1c9a-5bc5-459a-9b76-429a8327e0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc, test_error_count = test_reward_model(prefnet, test_set, images, patterns, batch_size)\n",
    "print(test_acc, test_error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9387be0-340d-4943-b2a3-cd2de80487f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989687399291009"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a09338-b63e-4224-9c6f-04372557325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prefnet, './human_comparisons/reward_model_v2_0.900.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b10c330-808f-4afa-807d-aa32449c6c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.1666666666666665 tensor([[0.1454]])\n",
      "1 3.0 tensor([[0.1484]])\n",
      "2 3.6666666666666665 tensor([[0.8452]])\n",
      "3 4.166666666666667 tensor([[0.8452]])\n",
      "4 3.333333333333333 tensor([[0.1452]])\n",
      "5 3.6666666666666665 tensor([[0.8389]])\n",
      "6 3.8333333333333335 tensor([[0.8449]])\n",
      "7 3.1666666666666665 tensor([[0.1467]])\n",
      "8 3.0 tensor([[0.1584]])\n",
      "9 2.333333333333333 tensor([[0.1468]])\n",
      "10 4.166666666666667 tensor([[0.8443]])\n",
      "11 2.833333333333333 tensor([[0.1451]])\n",
      "12 2.6666666666666665 tensor([[0.1485]])\n",
      "13 3.0 tensor([[0.1624]])\n",
      "14 3.0 tensor([[0.1454]])\n",
      "15 3.8333333333333335 tensor([[0.8440]])\n",
      "16 3.0 tensor([[0.1463]])\n",
      "17 3.6666666666666665 tensor([[0.8427]])\n",
      "18 3.0 tensor([[0.1456]])\n",
      "19 3.6666666666666665 tensor([[0.8448]])\n",
      "20 3.0 tensor([[0.1463]])\n",
      "21 3.1666666666666665 tensor([[0.1483]])\n",
      "22 3.5 tensor([[0.8449]])\n",
      "23 3.333333333333333 tensor([[0.1445]])\n",
      "24 3.5 tensor([[0.8444]])\n",
      "25 3.5 tensor([[0.3008]])\n",
      "26 3.1666666666666665 tensor([[0.3970]])\n",
      "27 3.5 tensor([[0.8430]])\n",
      "28 2.833333333333333 tensor([[0.1448]])\n",
      "29 3.0 tensor([[0.1448]])\n",
      "30 3.1666666666666665 tensor([[0.1695]])\n",
      "31 3.0 tensor([[0.1454]])\n",
      "32 3.8333333333333335 tensor([[0.8432]])\n",
      "33 3.5 tensor([[0.8420]])\n",
      "34 3.5 tensor([[0.8444]])\n",
      "35 3.1666666666666665 tensor([[0.1460]])\n",
      "36 3.5 tensor([[0.7171]])\n",
      "37 3.1666666666666665 tensor([[0.8327]])\n",
      "38 3.8333333333333335 tensor([[0.8447]])\n",
      "39 2.5 tensor([[0.1461]])\n",
      "40 3.333333333333333 tensor([[0.1507]])\n",
      "41 4.0 tensor([[0.8445]])\n",
      "42 3.0 tensor([[0.1450]])\n",
      "43 3.333333333333333 tensor([[0.1678]])\n",
      "44 3.6666666666666665 tensor([[0.8439]])\n",
      "45 4.0 tensor([[0.8452]])\n",
      "46 3.0 tensor([[0.1449]])\n",
      "47 3.8333333333333335 tensor([[0.8452]])\n",
      "48 3.0 tensor([[0.1528]])\n",
      "49 2.833333333333333 tensor([[0.1738]])\n",
      "50 3.333333333333333 tensor([[0.1711]])\n",
      "51 3.1666666666666665 tensor([[0.1695]])\n",
      "52 4.333333333333333 tensor([[0.8452]])\n",
      "53 3.6666666666666665 tensor([[0.1847]])\n",
      "54 3.5 tensor([[0.8438]])\n",
      "55 3.333333333333333 tensor([[0.1471]])\n",
      "56 3.1666666666666665 tensor([[0.1463]])\n",
      "57 3.1666666666666665 tensor([[0.1444]])\n",
      "58 3.0 tensor([[0.1448]])\n",
      "59 3.1666666666666665 tensor([[0.1454]])\n",
      "60 3.1666666666666665 tensor([[0.1491]])\n",
      "61 2.833333333333333 tensor([[0.1453]])\n",
      "62 3.6666666666666665 tensor([[0.1538]])\n",
      "63 2.1666666666666665 tensor([[0.1449]])\n",
      "64 2.833333333333333 tensor([[0.1569]])\n",
      "65 3.5 tensor([[0.1445]])\n",
      "66 3.6666666666666665 tensor([[0.8450]])\n",
      "67 4.166666666666667 tensor([[0.8443]])\n",
      "68 3.8333333333333335 tensor([[0.8450]])\n",
      "69 3.8333333333333335 tensor([[0.8423]])\n",
      "70 3.0 tensor([[0.1445]])\n",
      "71 2.6666666666666665 tensor([[0.1466]])\n",
      "72 3.8333333333333335 tensor([[0.8443]])\n",
      "73 4.166666666666667 tensor([[0.8393]])\n",
      "74 3.333333333333333 tensor([[0.1477]])\n",
      "75 3.5 tensor([[0.7860]])\n",
      "76 4.0 tensor([[0.8448]])\n",
      "77 3.333333333333333 tensor([[0.3306]])\n",
      "78 3.6666666666666665 tensor([[0.8435]])\n",
      "79 3.6666666666666665 tensor([[0.8438]])\n",
      "80 3.5 tensor([[0.8452]])\n",
      "81 3.8333333333333335 tensor([[0.8440]])\n",
      "82 3.333333333333333 tensor([[0.1524]])\n",
      "83 2.833333333333333 tensor([[0.1449]])\n",
      "84 4.333333333333333 tensor([[0.8375]])\n",
      "85 3.6666666666666665 tensor([[0.8432]])\n",
      "86 3.8333333333333335 tensor([[0.8439]])\n",
      "87 3.8333333333333335 tensor([[0.8432]])\n",
      "88 3.0 tensor([[0.1552]])\n",
      "89 4.0 tensor([[0.8449]])\n",
      "90 3.8333333333333335 tensor([[0.8441]])\n",
      "91 3.6666666666666665 tensor([[0.8454]])\n",
      "92 3.333333333333333 tensor([[0.1729]])\n",
      "93 3.8333333333333335 tensor([[0.8328]])\n",
      "94 3.5 tensor([[0.8445]])\n",
      "95 3.1666666666666665 tensor([[0.2476]])\n",
      "96 3.1666666666666665 tensor([[0.1891]])\n",
      "97 3.8333333333333335 tensor([[0.8437]])\n",
      "98 3.5 tensor([[0.8388]])\n",
      "99 2.5 tensor([[0.1456]])\n",
      "100 3.6666666666666665 tensor([[0.1847]])\n",
      "101 3.1666666666666665 tensor([[0.1515]])\n",
      "102 3.1666666666666665 tensor([[0.1637]])\n",
      "103 4.166666666666667 tensor([[0.8447]])\n",
      "104 3.0 tensor([[0.1447]])\n",
      "105 3.1666666666666665 tensor([[0.1528]])\n",
      "106 3.6666666666666665 tensor([[0.8452]])\n",
      "107 4.166666666666667 tensor([[0.8446]])\n",
      "108 3.5 tensor([[0.8412]])\n",
      "109 3.1666666666666665 tensor([[0.1580]])\n",
      "110 3.5 tensor([[0.1499]])\n",
      "111 3.333333333333333 tensor([[0.1914]])\n",
      "112 3.5 tensor([[0.8435]])\n",
      "113 2.833333333333333 tensor([[0.1535]])\n",
      "114 3.1666666666666665 tensor([[0.1622]])\n",
      "115 2.6666666666666665 tensor([[0.1448]])\n",
      "116 4.0 tensor([[0.8441]])\n",
      "117 3.0 tensor([[0.1450]])\n",
      "118 3.333333333333333 tensor([[0.7976]])\n",
      "119 2.5 tensor([[0.1456]])\n",
      "120 3.5 tensor([[0.8382]])\n",
      "121 3.6666666666666665 tensor([[0.8449]])\n",
      "122 3.1666666666666665 tensor([[0.1500]])\n",
      "123 3.5 tensor([[0.8275]])\n",
      "124 3.333333333333333 tensor([[0.1593]])\n",
      "125 3.1666666666666665 tensor([[0.5411]])\n",
      "126 3.6666666666666665 tensor([[0.8433]])\n",
      "127 2.1666666666666665 tensor([[0.1635]])\n",
      "128 3.5 tensor([[0.8399]])\n",
      "129 3.8333333333333335 tensor([[0.8444]])\n",
      "130 3.5 tensor([[0.8420]])\n",
      "131 3.0 tensor([[0.1477]])\n",
      "132 3.1666666666666665 tensor([[0.1663]])\n",
      "133 2.6666666666666665 tensor([[0.1446]])\n",
      "134 2.0 tensor([[0.1447]])\n",
      "135 3.0 tensor([[0.1480]])\n",
      "136 3.333333333333333 tensor([[0.1847]])\n",
      "137 2.1666666666666665 tensor([[0.1449]])\n",
      "138 3.8333333333333335 tensor([[0.8452]])\n",
      "139 3.1666666666666665 tensor([[0.1446]])\n",
      "140 3.6666666666666665 tensor([[0.8454]])\n",
      "141 3.333333333333333 tensor([[0.1512]])\n",
      "142 2.6666666666666665 tensor([[0.1455]])\n",
      "143 3.8333333333333335 tensor([[0.8427]])\n",
      "144 2.333333333333333 tensor([[0.1448]])\n",
      "145 3.5 tensor([[0.1529]])\n",
      "146 2.6666666666666665 tensor([[0.1489]])\n",
      "147 3.1666666666666665 tensor([[0.1466]])\n",
      "148 3.5 tensor([[0.1759]])\n",
      "149 3.6666666666666665 tensor([[0.8436]])\n",
      "150 4.333333333333333 tensor([[0.8446]])\n",
      "151 2.6666666666666665 tensor([[0.1456]])\n",
      "152 2.833333333333333 tensor([[0.1453]])\n",
      "153 3.333333333333333 tensor([[0.1493]])\n",
      "154 3.8333333333333335 tensor([[0.8452]])\n",
      "155 3.6666666666666665 tensor([[0.8391]])\n",
      "156 3.8333333333333335 tensor([[0.8362]])\n",
      "157 3.0 tensor([[0.1445]])\n",
      "158 3.0 tensor([[0.1463]])\n",
      "159 3.333333333333333 tensor([[0.1522]])\n",
      "160 3.333333333333333 tensor([[0.1578]])\n",
      "161 3.0 tensor([[0.1502]])\n",
      "162 2.833333333333333 tensor([[0.1475]])\n",
      "163 3.333333333333333 tensor([[0.1449]])\n",
      "164 3.333333333333333 tensor([[0.1521]])\n",
      "165 3.1666666666666665 tensor([[0.1743]])\n",
      "166 4.0 tensor([[0.8445]])\n",
      "167 4.166666666666667 tensor([[0.8437]])\n",
      "168 3.1666666666666665 tensor([[0.1445]])\n",
      "169 3.0 tensor([[0.1476]])\n",
      "170 3.8333333333333335 tensor([[0.8452]])\n",
      "171 3.8333333333333335 tensor([[0.8423]])\n",
      "172 4.0 tensor([[0.8448]])\n",
      "173 2.5 tensor([[0.1548]])\n",
      "174 3.1666666666666665 tensor([[0.4594]])\n",
      "175 4.0 tensor([[0.8439]])\n",
      "176 3.5 tensor([[0.8444]])\n",
      "177 3.5 tensor([[0.8448]])\n",
      "178 2.833333333333333 tensor([[0.1452]])\n",
      "179 3.1666666666666665 tensor([[0.1491]])\n",
      "180 3.6666666666666665 tensor([[0.1571]])\n",
      "181 3.1666666666666665 tensor([[0.1475]])\n",
      "182 3.333333333333333 tensor([[0.1506]])\n",
      "183 3.8333333333333335 tensor([[0.8452]])\n",
      "184 2.333333333333333 tensor([[0.1449]])\n",
      "185 4.333333333333333 tensor([[0.8422]])\n",
      "186 3.0 tensor([[0.1479]])\n",
      "187 3.6666666666666665 tensor([[0.8411]])\n",
      "188 2.333333333333333 tensor([[0.1444]])\n",
      "189 4.333333333333333 tensor([[0.8406]])\n",
      "190 3.5 tensor([[0.8409]])\n",
      "191 3.333333333333333 tensor([[0.1461]])\n",
      "192 3.6666666666666665 tensor([[0.8445]])\n",
      "193 3.6666666666666665 tensor([[0.8443]])\n",
      "194 3.6666666666666665 tensor([[0.8445]])\n",
      "195 2.833333333333333 tensor([[0.1563]])\n",
      "196 3.1666666666666665 tensor([[0.1476]])\n",
      "197 3.1666666666666665 tensor([[0.1479]])\n",
      "198 4.0 tensor([[0.8439]])\n",
      "199 3.333333333333333 tensor([[0.8385]])\n",
      "200 3.5 tensor([[0.8229]])\n",
      "201 3.333333333333333 tensor([[0.1634]])\n",
      "202 4.0 tensor([[0.8442]])\n",
      "203 2.833333333333333 tensor([[0.2494]])\n",
      "204 3.6666666666666665 tensor([[0.8412]])\n",
      "205 3.333333333333333 tensor([[0.1514]])\n",
      "206 3.6666666666666665 tensor([[0.7224]])\n",
      "207 3.0 tensor([[0.1500]])\n",
      "208 3.333333333333333 tensor([[0.1446]])\n",
      "209 2.333333333333333 tensor([[0.1448]])\n",
      "210 3.5 tensor([[0.8393]])\n",
      "211 4.166666666666667 tensor([[0.8440]])\n",
      "212 3.333333333333333 tensor([[0.2957]])\n",
      "213 3.0 tensor([[0.1459]])\n",
      "214 3.0 tensor([[0.8445]])\n",
      "215 3.333333333333333 tensor([[0.1464]])\n",
      "216 3.8333333333333335 tensor([[0.8189]])\n",
      "217 3.8333333333333335 tensor([[0.8410]])\n",
      "218 2.6666666666666665 tensor([[0.1477]])\n",
      "219 3.1666666666666665 tensor([[0.1449]])\n",
      "220 3.5 tensor([[0.8123]])\n",
      "221 3.8333333333333335 tensor([[0.8445]])\n",
      "222 3.8333333333333335 tensor([[0.4441]])\n",
      "223 3.5 tensor([[0.8419]])\n",
      "224 3.5 tensor([[0.8430]])\n",
      "225 3.6666666666666665 tensor([[0.8144]])\n",
      "226 4.0 tensor([[0.7885]])\n",
      "227 2.5 tensor([[0.1500]])\n",
      "228 3.0 tensor([[0.1472]])\n",
      "229 3.0 tensor([[0.1447]])\n",
      "230 2.333333333333333 tensor([[0.1469]])\n",
      "231 3.1666666666666665 tensor([[0.1847]])\n",
      "232 3.0 tensor([[0.1446]])\n",
      "233 4.166666666666667 tensor([[0.2719]])\n",
      "234 2.5 tensor([[0.1586]])\n",
      "235 2.333333333333333 tensor([[0.1459]])\n",
      "236 3.8333333333333335 tensor([[0.8407]])\n",
      "237 3.8333333333333335 tensor([[0.8448]])\n",
      "238 3.5 tensor([[0.2723]])\n",
      "239 3.5 tensor([[0.1549]])\n",
      "240 3.1666666666666665 tensor([[0.1478]])\n",
      "241 3.5 tensor([[0.8348]])\n",
      "242 3.8333333333333335 tensor([[0.8452]])\n",
      "243 3.6666666666666665 tensor([[0.8444]])\n",
      "244 3.6666666666666665 tensor([[0.8437]])\n",
      "245 4.0 tensor([[0.8449]])\n",
      "246 3.333333333333333 tensor([[0.1508]])\n",
      "247 3.8333333333333335 tensor([[0.8449]])\n",
      "248 4.0 tensor([[0.8379]])\n",
      "249 2.833333333333333 tensor([[0.1526]])\n",
      "250 3.6666666666666665 tensor([[0.6940]])\n",
      "251 2.833333333333333 tensor([[0.1447]])\n",
      "252 2.5 tensor([[0.1447]])\n",
      "253 3.5 tensor([[0.8454]])\n",
      "254 3.333333333333333 tensor([[0.1570]])\n",
      "255 3.1666666666666665 tensor([[0.1483]])\n",
      "256 3.5 tensor([[0.7725]])\n",
      "257 3.0 tensor([[0.1491]])\n",
      "258 4.166666666666667 tensor([[0.8446]])\n",
      "259 4.0 tensor([[0.8435]])\n",
      "260 3.1666666666666665 tensor([[0.1458]])\n",
      "261 3.6666666666666665 tensor([[0.8380]])\n",
      "262 3.6666666666666665 tensor([[0.8444]])\n",
      "263 3.333333333333333 tensor([[0.1536]])\n",
      "264 4.5 tensor([[0.8455]])\n",
      "265 2.833333333333333 tensor([[0.1445]])\n",
      "266 2.833333333333333 tensor([[0.1446]])\n",
      "267 2.833333333333333 tensor([[0.1475]])\n",
      "268 4.0 tensor([[0.8450]])\n",
      "269 3.1666666666666665 tensor([[0.1470]])\n",
      "270 2.6666666666666665 tensor([[0.1479]])\n",
      "271 1.8333333333333333 tensor([[0.1447]])\n",
      "272 3.333333333333333 tensor([[0.3709]])\n",
      "273 4.166666666666667 tensor([[0.8432]])\n",
      "274 3.1666666666666665 tensor([[0.1448]])\n",
      "275 3.0 tensor([[0.1495]])\n",
      "276 3.333333333333333 tensor([[0.1593]])\n",
      "277 3.1666666666666665 tensor([[0.1448]])\n",
      "278 2.833333333333333 tensor([[0.1465]])\n",
      "279 3.5 tensor([[0.8438]])\n",
      "280 3.6666666666666665 tensor([[0.8441]])\n",
      "281 2.833333333333333 tensor([[0.1471]])\n",
      "282 3.1666666666666665 tensor([[0.1556]])\n",
      "283 3.333333333333333 tensor([[0.1460]])\n",
      "284 2.5 tensor([[0.1518]])\n",
      "285 3.0 tensor([[0.1447]])\n",
      "286 3.6666666666666665 tensor([[0.8451]])\n",
      "287 3.6666666666666665 tensor([[0.8449]])\n",
      "288 3.1666666666666665 tensor([[0.8425]])\n",
      "289 3.0 tensor([[0.1449]])\n",
      "290 3.5 tensor([[0.8451]])\n",
      "291 3.6666666666666665 tensor([[0.8393]])\n",
      "292 2.333333333333333 tensor([[0.1477]])\n",
      "293 3.6666666666666665 tensor([[0.8454]])\n",
      "294 4.166666666666667 tensor([[0.8443]])\n",
      "295 2.833333333333333 tensor([[0.1466]])\n",
      "296 3.1666666666666665 tensor([[0.1847]])\n",
      "297 4.333333333333333 tensor([[0.8445]])\n",
      "298 3.8333333333333335 tensor([[0.8438]])\n",
      "299 3.333333333333333 tensor([[0.1472]])\n",
      "300 3.1666666666666665 tensor([[0.1511]])\n",
      "301 3.1666666666666665 tensor([[0.1467]])\n",
      "302 4.0 tensor([[0.8452]])\n",
      "303 3.5 tensor([[0.8423]])\n",
      "304 4.0 tensor([[0.8434]])\n",
      "305 3.333333333333333 tensor([[0.3953]])\n",
      "306 3.0 tensor([[0.1447]])\n",
      "307 3.333333333333333 tensor([[0.1495]])\n",
      "308 3.333333333333333 tensor([[0.1459]])\n",
      "309 3.0 tensor([[0.1548]])\n",
      "310 3.5 tensor([[0.8350]])\n",
      "311 2.6666666666666665 tensor([[0.1965]])\n",
      "312 3.333333333333333 tensor([[0.1464]])\n",
      "313 3.8333333333333335 tensor([[0.8447]])\n",
      "314 3.5 tensor([[0.8449]])\n",
      "315 4.0 tensor([[0.8454]])\n",
      "316 3.0 tensor([[0.1464]])\n",
      "317 3.5 tensor([[0.1445]])\n",
      "318 3.6666666666666665 tensor([[0.8454]])\n",
      "319 2.6666666666666665 tensor([[0.1518]])\n",
      "320 3.333333333333333 tensor([[0.1497]])\n",
      "321 4.5 tensor([[0.8452]])\n",
      "322 2.833333333333333 tensor([[0.1464]])\n",
      "323 3.8333333333333335 tensor([[0.8426]])\n",
      "324 3.6666666666666665 tensor([[0.8454]])\n",
      "325 3.333333333333333 tensor([[0.1445]])\n",
      "326 4.166666666666667 tensor([[0.8454]])\n",
      "327 2.833333333333333 tensor([[0.1444]])\n",
      "328 3.8333333333333335 tensor([[0.8450]])\n",
      "329 4.0 tensor([[0.8454]])\n",
      "330 4.333333333333333 tensor([[0.8444]])\n",
      "331 3.8333333333333335 tensor([[0.8420]])\n",
      "332 4.0 tensor([[0.8376]])\n",
      "333 3.0 tensor([[0.1445]])\n",
      "334 1.6666666666666667 tensor([[0.1444]])\n",
      "335 3.6666666666666665 tensor([[0.8120]])\n",
      "336 3.333333333333333 tensor([[0.1467]])\n",
      "337 3.8333333333333335 tensor([[0.8447]])\n",
      "338 3.6666666666666665 tensor([[0.8451]])\n",
      "339 3.8333333333333335 tensor([[0.8446]])\n",
      "340 3.8333333333333335 tensor([[0.8442]])\n",
      "341 3.5 tensor([[0.1552]])\n",
      "342 4.0 tensor([[0.8451]])\n",
      "343 3.0 tensor([[0.1484]])\n",
      "344 3.6666666666666665 tensor([[0.8452]])\n",
      "345 3.5 tensor([[0.8450]])\n",
      "346 2.6666666666666665 tensor([[0.1490]])\n",
      "347 4.666666666666667 tensor([[0.8446]])\n",
      "348 2.833333333333333 tensor([[0.1444]])\n",
      "349 2.6666666666666665 tensor([[0.1464]])\n",
      "350 3.333333333333333 tensor([[0.1521]])\n",
      "351 3.6666666666666665 tensor([[0.8454]])\n",
      "352 2.6666666666666665 tensor([[0.1487]])\n",
      "353 3.5 tensor([[0.1496]])\n",
      "354 2.833333333333333 tensor([[0.1454]])\n",
      "355 4.333333333333333 tensor([[0.8444]])\n",
      "356 3.8333333333333335 tensor([[0.8445]])\n",
      "357 3.333333333333333 tensor([[0.8447]])\n",
      "358 3.333333333333333 tensor([[0.2072]])\n",
      "359 3.1666666666666665 tensor([[0.1445]])\n",
      "360 3.6666666666666665 tensor([[0.8451]])\n",
      "361 3.6666666666666665 tensor([[0.8450]])\n",
      "362 4.5 tensor([[0.8452]])\n",
      "363 3.5 tensor([[0.8450]])\n",
      "364 3.6666666666666665 tensor([[0.8432]])\n",
      "365 4.333333333333333 tensor([[0.8452]])\n",
      "366 3.1666666666666665 tensor([[0.1834]])\n",
      "367 3.0 tensor([[0.1447]])\n",
      "368 3.1666666666666665 tensor([[0.1526]])\n",
      "369 3.6666666666666665 tensor([[0.8346]])\n",
      "370 3.5 tensor([[0.1682]])\n",
      "371 4.166666666666667 tensor([[0.8430]])\n",
      "372 3.5 tensor([[0.1523]])\n",
      "373 3.333333333333333 tensor([[0.1609]])\n",
      "374 2.833333333333333 tensor([[0.1444]])\n",
      "375 3.333333333333333 tensor([[0.1832]])\n",
      "376 3.1666666666666665 tensor([[0.1572]])\n",
      "377 3.1666666666666665 tensor([[0.1513]])\n",
      "378 3.5 tensor([[0.8441]])\n",
      "379 2.833333333333333 tensor([[0.1483]])\n",
      "380 3.0 tensor([[0.1461]])\n",
      "381 3.6666666666666665 tensor([[0.8434]])\n",
      "382 3.333333333333333 tensor([[0.2490]])\n",
      "383 3.6666666666666665 tensor([[0.8448]])\n",
      "384 3.5 tensor([[0.8446]])\n",
      "385 3.6666666666666665 tensor([[0.8405]])\n",
      "386 4.0 tensor([[0.8447]])\n",
      "387 3.6666666666666665 tensor([[0.8452]])\n",
      "388 4.333333333333333 tensor([[0.8430]])\n",
      "389 3.5 tensor([[0.8451]])\n",
      "390 3.8333333333333335 tensor([[0.8448]])\n",
      "391 3.0 tensor([[0.1461]])\n",
      "392 3.5 tensor([[0.8452]])\n",
      "393 3.333333333333333 tensor([[0.1567]])\n",
      "394 4.166666666666667 tensor([[0.8454]])\n",
      "395 3.0 tensor([[0.1461]])\n",
      "396 3.8333333333333335 tensor([[0.8444]])\n",
      "397 4.0 tensor([[0.8449]])\n",
      "398 3.5 tensor([[0.1685]])\n",
      "399 3.1666666666666665 tensor([[0.1715]])\n",
      "400 2.833333333333333 tensor([[0.1449]])\n",
      "401 3.0 tensor([[0.1500]])\n",
      "402 3.1666666666666665 tensor([[0.1446]])\n",
      "403 4.0 tensor([[0.8392]])\n",
      "404 3.333333333333333 tensor([[0.1608]])\n",
      "405 3.1666666666666665 tensor([[0.1445]])\n",
      "406 3.333333333333333 tensor([[0.1812]])\n",
      "407 3.6666666666666665 tensor([[0.8450]])\n",
      "408 3.333333333333333 tensor([[0.1450]])\n",
      "409 3.5 tensor([[0.1446]])\n",
      "410 3.333333333333333 tensor([[0.1847]])\n",
      "411 3.5 tensor([[0.8444]])\n",
      "412 2.5 tensor([[0.1444]])\n",
      "413 3.1666666666666665 tensor([[0.1656]])\n",
      "414 3.6666666666666665 tensor([[0.1449]])\n",
      "415 3.5 tensor([[0.8443]])\n",
      "416 3.6666666666666665 tensor([[0.8454]])\n",
      "417 3.5 tensor([[0.8418]])\n",
      "418 3.1666666666666665 tensor([[0.1469]])\n",
      "419 4.0 tensor([[0.8449]])\n",
      "420 4.0 tensor([[0.8418]])\n",
      "421 2.833333333333333 tensor([[0.1650]])\n",
      "422 4.0 tensor([[0.8445]])\n",
      "423 4.0 tensor([[0.8432]])\n",
      "424 3.333333333333333 tensor([[0.1445]])\n",
      "425 4.166666666666667 tensor([[0.8452]])\n",
      "426 3.6666666666666665 tensor([[0.8057]])\n",
      "427 2.6666666666666665 tensor([[0.1462]])\n",
      "428 3.5 tensor([[0.8387]])\n",
      "429 3.333333333333333 tensor([[0.1452]])\n",
      "430 2.833333333333333 tensor([[0.1445]])\n",
      "431 3.6666666666666665 tensor([[0.8438]])\n",
      "432 3.8333333333333335 tensor([[0.8442]])\n",
      "433 3.333333333333333 tensor([[0.8331]])\n",
      "434 3.5 tensor([[0.8440]])\n",
      "435 3.6666666666666665 tensor([[0.8405]])\n",
      "436 4.0 tensor([[0.8452]])\n",
      "437 3.333333333333333 tensor([[0.1460]])\n",
      "438 3.8333333333333335 tensor([[0.8392]])\n",
      "439 4.0 tensor([[0.8452]])\n",
      "440 3.6666666666666665 tensor([[0.8399]])\n",
      "441 4.0 tensor([[0.8431]])\n",
      "442 4.0 tensor([[0.8430]])\n",
      "443 3.5 tensor([[0.3491]])\n",
      "444 3.8333333333333335 tensor([[0.8451]])\n",
      "445 3.0 tensor([[0.1494]])\n",
      "446 3.333333333333333 tensor([[0.1655]])\n",
      "447 3.6666666666666665 tensor([[0.8432]])\n",
      "448 3.333333333333333 tensor([[0.1463]])\n",
      "449 3.333333333333333 tensor([[0.1471]])\n",
      "450 3.5 tensor([[0.6064]])\n",
      "451 4.166666666666667 tensor([[0.8452]])\n",
      "452 3.333333333333333 tensor([[0.1445]])\n",
      "453 2.5 tensor([[0.1446]])\n",
      "454 3.1666666666666665 tensor([[0.3954]])\n",
      "455 3.5 tensor([[0.8434]])\n",
      "456 3.333333333333333 tensor([[0.1488]])\n",
      "457 3.6666666666666665 tensor([[0.8452]])\n",
      "458 4.333333333333333 tensor([[0.8221]])\n",
      "459 3.0 tensor([[0.1456]])\n",
      "460 3.5 tensor([[0.8452]])\n",
      "461 4.0 tensor([[0.8448]])\n",
      "462 3.6666666666666665 tensor([[0.6559]])\n",
      "463 2.833333333333333 tensor([[0.1523]])\n",
      "464 3.6666666666666665 tensor([[0.8424]])\n",
      "465 3.0 tensor([[0.1519]])\n",
      "466 4.0 tensor([[0.8453]])\n",
      "467 4.166666666666667 tensor([[0.8305]])\n",
      "468 3.8333333333333335 tensor([[0.8452]])\n",
      "469 3.0 tensor([[0.1482]])\n",
      "470 3.6666666666666665 tensor([[0.8442]])\n",
      "471 3.8333333333333335 tensor([[0.8452]])\n",
      "472 3.8333333333333335 tensor([[0.8451]])\n",
      "473 3.8333333333333335 tensor([[0.8377]])\n",
      "474 3.5 tensor([[0.8449]])\n",
      "475 3.333333333333333 tensor([[0.1457]])\n",
      "476 3.0 tensor([[0.1647]])\n",
      "477 3.0 tensor([[0.1557]])\n",
      "478 2.833333333333333 tensor([[0.1444]])\n",
      "479 3.6666666666666665 tensor([[0.8452]])\n",
      "480 3.333333333333333 tensor([[0.1477]])\n",
      "481 3.333333333333333 tensor([[0.1480]])\n",
      "482 3.8333333333333335 tensor([[0.8442]])\n",
      "483 3.5 tensor([[0.5679]])\n",
      "484 3.333333333333333 tensor([[0.4383]])\n",
      "485 3.1666666666666665 tensor([[0.1464]])\n",
      "486 3.0 tensor([[0.1465]])\n",
      "487 3.5 tensor([[0.5120]])\n",
      "488 3.1666666666666665 tensor([[0.2152]])\n",
      "489 2.833333333333333 tensor([[0.8440]])\n",
      "490 3.333333333333333 tensor([[0.7519]])\n",
      "491 4.0 tensor([[0.5844]])\n",
      "492 3.1666666666666665 tensor([[0.3752]])\n",
      "493 3.5 tensor([[0.8384]])\n",
      "494 4.166666666666667 tensor([[0.7609]])\n",
      "495 3.8333333333333335 tensor([[0.8439]])\n",
      "496 3.6666666666666665 tensor([[0.8434]])\n",
      "497 4.0 tensor([[0.6834]])\n",
      "498 3.0 tensor([[0.3054]])\n",
      "499 3.333333333333333 tensor([[0.5843]])\n",
      "500 3.1666666666666665 tensor([[0.8372]])\n",
      "501 3.333333333333333 tensor([[0.8377]])\n",
      "502 3.5 tensor([[0.8249]])\n",
      "503 3.8333333333333335 tensor([[0.8312]])\n",
      "504 2.833333333333333 tensor([[0.7328]])\n",
      "505 4.166666666666667 tensor([[0.8446]])\n",
      "506 4.0 tensor([[0.8447]])\n",
      "507 3.1666666666666665 tensor([[0.1494]])\n",
      "508 3.8333333333333335 tensor([[0.8425]])\n",
      "509 2.6666666666666665 tensor([[0.4189]])\n",
      "510 3.6666666666666665 tensor([[0.1536]])\n",
      "511 3.0 tensor([[0.4345]])\n",
      "512 3.8333333333333335 tensor([[0.1455]])\n",
      "513 2.833333333333333 tensor([[0.2256]])\n",
      "514 4.166666666666667 tensor([[0.8419]])\n",
      "515 3.8333333333333335 tensor([[0.7544]])\n",
      "516 3.6666666666666665 tensor([[0.1462]])\n",
      "517 3.333333333333333 tensor([[0.2338]])\n",
      "518 4.5 tensor([[0.7729]])\n",
      "519 4.0 tensor([[0.2786]])\n",
      "520 2.5 tensor([[0.3199]])\n",
      "521 3.8333333333333335 tensor([[0.8413]])\n",
      "522 4.166666666666667 tensor([[0.1445]])\n",
      "523 3.5 tensor([[0.7598]])\n",
      "524 3.6666666666666665 tensor([[0.8423]])\n",
      "525 4.166666666666667 tensor([[0.4148]])\n",
      "526 4.333333333333333 tensor([[0.1536]])\n",
      "527 3.333333333333333 tensor([[0.3727]])\n",
      "528 3.6666666666666665 tensor([[0.7855]])\n",
      "529 3.0 tensor([[0.8444]])\n",
      "530 3.6666666666666665 tensor([[0.8338]])\n",
      "531 3.1666666666666665 tensor([[0.2040]])\n",
      "532 4.0 tensor([[0.1453]])\n",
      "533 3.5 tensor([[0.2460]])\n",
      "534 3.333333333333333 tensor([[0.3156]])\n",
      "535 3.1666666666666665 tensor([[0.1483]])\n",
      "536 2.5 tensor([[0.5344]])\n",
      "537 2.5 tensor([[0.8417]])\n",
      "538 4.0 tensor([[0.5308]])\n",
      "539 4.166666666666667 tensor([[0.1640]])\n",
      "540 3.0 tensor([[0.7536]])\n",
      "541 2.833333333333333 tensor([[0.6069]])\n",
      "542 3.6666666666666665 tensor([[0.8442]])\n",
      "543 4.0 tensor([[0.5351]])\n",
      "544 3.6666666666666665 tensor([[0.8348]])\n",
      "545 3.333333333333333 tensor([[0.2556]])\n",
      "546 4.666666666666667 tensor([[0.4892]])\n",
      "547 3.6666666666666665 tensor([[0.5526]])\n",
      "548 2.5 tensor([[0.8344]])\n",
      "549 3.6666666666666665 tensor([[0.5365]])\n",
      "550 2.833333333333333 tensor([[0.7978]])\n",
      "551 3.333333333333333 tensor([[0.8431]])\n",
      "552 2.1666666666666665 tensor([[0.6127]])\n",
      "553 4.5 tensor([[0.8410]])\n",
      "554 4.166666666666667 tensor([[0.4580]])\n",
      "555 4.166666666666667 tensor([[0.8365]])\n",
      "556 3.5 tensor([[0.8404]])\n",
      "557 4.0 tensor([[0.8450]])\n",
      "558 3.8333333333333335 tensor([[0.8446]])\n",
      "559 3.333333333333333 tensor([[0.8343]])\n",
      "560 3.333333333333333 tensor([[0.1451]])\n",
      "561 2.6666666666666665 tensor([[0.1502]])\n",
      "562 2.833333333333333 tensor([[0.8395]])\n",
      "563 3.8333333333333335 tensor([[0.1446]])\n",
      "564 2.833333333333333 tensor([[0.8424]])\n",
      "565 3.5 tensor([[0.4366]])\n",
      "566 3.333333333333333 tensor([[0.4745]])\n",
      "567 3.1666666666666665 tensor([[0.1491]])\n",
      "568 3.6666666666666665 tensor([[0.2381]])\n",
      "569 4.0 tensor([[0.8430]])\n",
      "570 3.0 tensor([[0.8444]])\n",
      "571 3.333333333333333 tensor([[0.3685]])\n",
      "572 4.0 tensor([[0.8450]])\n",
      "573 3.6666666666666665 tensor([[0.8452]])\n",
      "574 4.333333333333333 tensor([[0.8452]])\n",
      "575 3.6666666666666665 tensor([[0.2136]])\n",
      "576 3.1666666666666665 tensor([[0.8449]])\n",
      "577 3.6666666666666665 tensor([[0.1461]])\n",
      "578 3.1666666666666665 tensor([[0.1454]])\n",
      "579 4.333333333333333 tensor([[0.8027]])\n",
      "580 2.6666666666666665 tensor([[0.5086]])\n",
      "581 4.5 tensor([[0.8381]])\n",
      "582 3.0 tensor([[0.8452]])\n",
      "583 4.166666666666667 tensor([[0.8449]])\n",
      "584 4.166666666666667 tensor([[0.8405]])\n",
      "585 3.0 tensor([[0.8414]])\n",
      "586 3.8333333333333335 tensor([[0.7791]])\n",
      "587 3.6666666666666665 tensor([[0.8426]])\n",
      "588 4.0 tensor([[0.1444]])\n",
      "589 4.0 tensor([[0.1853]])\n",
      "590 3.0 tensor([[0.8419]])\n",
      "591 2.833333333333333 tensor([[0.2332]])\n",
      "592 3.5 tensor([[0.8131]])\n",
      "593 3.1666666666666665 tensor([[0.6490]])\n",
      "594 3.333333333333333 tensor([[0.1446]])\n",
      "595 3.8333333333333335 tensor([[0.3588]])\n",
      "596 3.5 tensor([[0.8383]])\n",
      "597 3.0 tensor([[0.1471]])\n",
      "598 4.166666666666667 tensor([[0.8444]])\n",
      "599 4.0 tensor([[0.7341]])\n",
      "600 3.6666666666666665 tensor([[0.6343]])\n",
      "601 3.333333333333333 tensor([[0.3255]])\n",
      "602 3.1666666666666665 tensor([[0.8277]])\n",
      "603 3.5 tensor([[0.5835]])\n",
      "604 3.0 tensor([[0.2042]])\n",
      "605 3.6666666666666665 tensor([[0.1491]])\n",
      "606 3.333333333333333 tensor([[0.1615]])\n",
      "607 4.0 tensor([[0.1628]])\n",
      "608 4.166666666666667 tensor([[0.1501]])\n",
      "609 2.6666666666666665 tensor([[0.8426]])\n",
      "610 3.333333333333333 tensor([[0.8420]])\n",
      "611 3.333333333333333 tensor([[0.8407]])\n",
      "612 3.0 tensor([[0.8393]])\n",
      "613 3.0 tensor([[0.8391]])\n",
      "614 3.1666666666666665 tensor([[0.8415]])\n",
      "615 3.0 tensor([[0.7798]])\n",
      "616 3.5 tensor([[0.8440]])\n",
      "617 3.333333333333333 tensor([[0.4294]])\n",
      "618 3.333333333333333 tensor([[0.8382]])\n",
      "619 3.333333333333333 tensor([[0.8294]])\n",
      "620 3.6666666666666665 tensor([[0.8439]])\n",
      "621 3.333333333333333 tensor([[0.1546]])\n",
      "622 3.333333333333333 tensor([[0.1703]])\n",
      "623 3.5 tensor([[0.6966]])\n",
      "624 3.1666666666666665 tensor([[0.8182]])\n",
      "625 3.5 tensor([[0.2395]])\n",
      "626 2.5 tensor([[0.5895]])\n",
      "627 2.833333333333333 tensor([[0.8332]])\n",
      "628 3.333333333333333 tensor([[0.2982]])\n",
      "629 4.5 tensor([[0.6848]])\n",
      "630 2.833333333333333 tensor([[0.2695]])\n",
      "631 4.333333333333333 tensor([[0.5205]])\n",
      "632 2.6666666666666665 tensor([[0.1563]])\n",
      "633 3.0 tensor([[0.8393]])\n",
      "634 3.6666666666666665 tensor([[0.7803]])\n",
      "635 3.6666666666666665 tensor([[0.6672]])\n",
      "636 3.0 tensor([[0.1623]])\n",
      "637 4.5 tensor([[0.8299]])\n",
      "638 2.333333333333333 tensor([[0.8453]])\n",
      "639 3.0 tensor([[0.8451]])\n",
      "640 3.5 tensor([[0.1580]])\n",
      "641 2.833333333333333 tensor([[0.1955]])\n",
      "642 3.1666666666666665 tensor([[0.1802]])\n",
      "643 4.166666666666667 tensor([[0.8375]])\n",
      "644 3.1666666666666665 tensor([[0.4597]])\n",
      "645 3.333333333333333 tensor([[0.1494]])\n",
      "646 3.8333333333333335 tensor([[0.1812]])\n",
      "647 3.5 tensor([[0.5375]])\n",
      "648 3.333333333333333 tensor([[0.1539]])\n",
      "649 2.1666666666666665 tensor([[0.4645]])\n",
      "650 3.0 tensor([[0.7594]])\n",
      "651 2.6666666666666665 tensor([[0.8435]])\n",
      "652 3.333333333333333 tensor([[0.8430]])\n",
      "653 3.0 tensor([[0.1951]])\n",
      "654 3.5 tensor([[0.8386]])\n",
      "655 2.833333333333333 tensor([[0.5608]])\n",
      "656 3.6666666666666665 tensor([[0.8327]])\n",
      "657 4.0 tensor([[0.4917]])\n",
      "658 3.1666666666666665 tensor([[0.3279]])\n",
      "659 3.1666666666666665 tensor([[0.1446]])\n",
      "660 3.0 tensor([[0.6761]])\n",
      "661 3.333333333333333 tensor([[0.6461]])\n",
      "662 3.0 tensor([[0.2547]])\n",
      "663 3.5 tensor([[0.7182]])\n",
      "664 4.666666666666667 tensor([[0.7060]])\n",
      "665 3.1666666666666665 tensor([[0.2867]])\n",
      "666 2.833333333333333 tensor([[0.2213]])\n",
      "667 4.166666666666667 tensor([[0.6961]])\n",
      "668 4.0 tensor([[0.7895]])\n",
      "669 3.5 tensor([[0.5283]])\n",
      "670 3.6666666666666665 tensor([[0.8402]])\n",
      "671 2.6666666666666665 tensor([[0.5867]])\n",
      "672 3.333333333333333 tensor([[0.1773]])\n",
      "673 2.5 tensor([[0.2871]])\n",
      "674 2.833333333333333 tensor([[0.1628]])\n",
      "675 3.5 tensor([[0.4917]])\n",
      "676 4.166666666666667 tensor([[0.8389]])\n",
      "677 3.1666666666666665 tensor([[0.8415]])\n",
      "678 3.0 tensor([[0.6431]])\n",
      "679 2.833333333333333 tensor([[0.1462]])\n",
      "680 3.0 tensor([[0.7298]])\n",
      "681 2.833333333333333 tensor([[0.6694]])\n",
      "682 3.333333333333333 tensor([[0.8405]])\n",
      "683 3.6666666666666665 tensor([[0.4600]])\n",
      "684 2.833333333333333 tensor([[0.3087]])\n",
      "685 4.0 tensor([[0.1448]])\n",
      "686 3.5 tensor([[0.8274]])\n",
      "687 2.833333333333333 tensor([[0.1799]])\n",
      "688 3.6666666666666665 tensor([[0.7932]])\n",
      "689 3.5 tensor([[0.3483]])\n",
      "690 3.1666666666666665 tensor([[0.8355]])\n"
     ]
    }
   ],
   "source": [
    "prefnet = torch.load('./human_comparisons/reward_model_v2_0.900.pth')\n",
    "scores = []\n",
    "for i in range(len(new_comp_df)):\n",
    "    score = prefnet(images[i].cuda(), patterns[i].cuda()).detach().cpu().data\n",
    "    scores.append(score)\n",
    "    print(i, new_comp_df.iloc[i]['rating'], score.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f668ba2b-8929-4b63-9b41-e411bc43c584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([284.,  17.,  14.,  10.,  14.,  12.,  10.,  12.,  15., 303.]),\n",
       " array([0.1443681 , 0.21448527, 0.28460243, 0.35471961, 0.42483678,\n",
       "        0.49495396, 0.56507111, 0.63518828, 0.70530546, 0.77542263,\n",
       "        0.84553981]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_scores = [x.data[0][0] for x in scores]\n",
    "plt.hist(predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9e198-6e38-4085-8bde-8e37201fd651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
