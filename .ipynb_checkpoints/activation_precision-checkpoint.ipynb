{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4602ef-3516-456e-99ff-09885b0d282e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch  \n",
    "import numpy as np  \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.distributions.categorical import Categorical\n",
    "import math\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "from settings import train_dir, test_dir, train_push_dir, train_batch_size, test_batch_size, train_push_batch_size\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, prototype_activation_function, add_on_layers_type\n",
    "from receptive_field import compute_rf_prototype\n",
    "import cv2\n",
    "#from reward_model import construct_PrefNet, paired_cross_entropy_loss, PrefNet\n",
    "from tqdm import tqdm\n",
    "from settings import joint_optimizer_lrs, joint_lr_step_size\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import train_and_test as tnt\n",
    "from torch.utils.data import Subset\n",
    "import time\n",
    "import heapq\n",
    "import model\n",
    "from PIL import Image\n",
    "import protopformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd2595f-2c2b-4a08-beac-4c5e93e59463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "img_preprocess = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "mask_preprocess = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        train_push_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=80, shuffle=False,\n",
    "    num_workers=1, pin_memory=False)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "        test_dir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(size=(img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False,\n",
    "    num_workers=1, pin_memory=False)\n",
    "\n",
    "mask_dir = './activation_mask/segmentations/'\n",
    "mask_dataset = datasets.ImageFolder(\n",
    "        mask_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "mask_loader = torch.utils.data.DataLoader(\n",
    "    mask_dataset, batch_size=test_batch_size, shuffle=False,\n",
    "    num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224d222b-b758-4b04-a3a8-b3765e509593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ProtoPFormer ProtoPFormer/output_cosine/CUB2011U/deit_tiny_patch16_224 ProtoPFormer/output_cosine/CUB2011U/deit_tiny_patch16_224/1028--adamw-0.05-200-protopformer/checkpoints\n",
    "base_architecture = 'cait_xxs24_224'\n",
    "num_classes = 200\n",
    "prototype_shape = [2000, 192, 1, 1]\n",
    "reserve_layers=[11]\n",
    "reserve_token_nums=[81]\n",
    "use_global=True\n",
    "use_ppc_loss=True\n",
    "ppc_cov_thresh=1.\n",
    "ppc_mean_thresh=2.\n",
    "global_coe=0.5\n",
    "global_proto_per_class=10\n",
    "prototype_activation_function='log'\n",
    "add_on_layers_type='regular'\n",
    "\n",
    "#ckpt = torch.load(f'../ProtoPFormer/output_cosine/CUB2011U/'+ base_architecture + ' ProtoPFormer/1028--adamw-0.05-200-protopformer/checkpoints/epoch-best.pth')\n",
    "ckpt = torch.load('../ProtoPFormer/output_cosine/CUB2011U/cait_xxs24_224/1028--adamw-0.05-200-protopformer/checkpoints/epoch-best.pth')\n",
    "ppnet = protopformer.construct_PPNet(base_architecture=base_architecture,\n",
    "                                pretrained=True, img_size=img_size,\n",
    "                                prototype_shape=prototype_shape,\n",
    "                                num_classes=num_classes,\n",
    "                                reserve_layers=reserve_layers,\n",
    "                                reserve_token_nums=reserve_token_nums,\n",
    "                                use_global=use_global,\n",
    "                                use_ppc_loss=use_ppc_loss,\n",
    "                                ppc_cov_thresh=ppc_cov_thresh,\n",
    "                                ppc_mean_thresh=ppc_mean_thresh,\n",
    "                                global_coe=global_coe,\n",
    "                                global_proto_per_class=global_proto_per_class,\n",
    "                                prototype_activation_function=prototype_activation_function,\n",
    "                                add_on_layers_type=add_on_layers_type)\n",
    "\n",
    "ppnet = ppnet.cuda()\n",
    "ppnet.load_state_dict(ckpt['model'])\n",
    "ppnet = torch.nn.DataParallel(ppnet)\n",
    "#pf_model = torch.load('./human_comparisons/pref_model_700_random_rating_split0.7_acc0.915.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540f803d-e14d-433f-ac26-0125d8a22184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5794 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'cls_token_attn' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m prototype_shape \u001b[38;5;241m=\u001b[39m ppnet\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mprototype_shape\n\u001b[1;32m     27\u001b[0m test_img \u001b[38;5;241m=\u001b[39m test_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 28\u001b[0m _, proto_acts \u001b[38;5;241m=\u001b[39m \u001b[43mppnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m proto_dist \u001b[38;5;241m=\u001b[39m proto_acts\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     31\u001b[0m local_img_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:340\u001b[0m, in \u001b[0;36mPPNet.push_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m'''this method is needed for the pushing operation'''\u001b[39;00m\n\u001b[1;32m    339\u001b[0m reserve_layer_nums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreserve_layer_nums\n\u001b[0;32m--> 340\u001b[0m (cls_tokens, img_tokens), (token_attn, cls_token_attn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprototype_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m global_activations, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_activations(cls_tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_vectors_global)\n\u001b[1;32m    342\u001b[0m local_activations, (distances, proto_acts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_activations(img_tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_vectors)\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:225\u001b[0m, in \u001b[0;36mPPNet.prototype_distances\u001b[0;34m(self, x, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mx is the raw input\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_global:\n\u001b[0;32m--> 225\u001b[0m     (cls_tokens, img_tokens), auxi_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (cls_tokens, img_tokens), auxi_item\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:155\u001b[0m, in \u001b[0;36mPPNet.conv_features\u001b[0;34m(self, x, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    152\u001b[0m fea_size, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x_embed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)), x_embed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    154\u001b[0m token_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m x, (cls_token_attn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_feature_mask_train_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m final_reserve_num \u001b[38;5;241m=\u001b[39m reserve_layer_nums[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m final_reserve_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(cls_token_attn, k\u001b[38;5;241m=\u001b[39mfinal_reserve_num, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# (B, final_reserve_num)\u001b[39;00m\n",
      "File \u001b[0;32m~/ProtoPNet/tools/cait_models_attn.py:346\u001b[0m, in \u001b[0;36mMyCait.forward_feature_mask_train_direct\u001b[0;34m(self, cls_embed, x_embed, token_attn, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    343\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    345\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, (\u001b[43mcls_token_attn\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'cls_token_attn' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "bad_img_idx = [193, 1764, 2472, 3082]\n",
    "#bad_img_idx = []\n",
    "percentile_threshold = 95\n",
    "#total_overlap = 0\n",
    "num_imgs = len(test_dataset.imgs)\n",
    "\n",
    "#GZ\n",
    "total_local_overlap = 0 \n",
    "total_global_overlap = 0 \n",
    "for i in tqdm(range(num_imgs)):\n",
    "    if i in bad_img_idx:\n",
    "        continue\n",
    "    test_img_dir = test_dataset.imgs[i][0]\n",
    "    sub_dir = test_img_dir[44:-4]\n",
    "    test_img = Image.open(test_img_dir)\n",
    "        \n",
    "    test_img = img_preprocess(test_img)\n",
    "    mask_img_dir = mask_dir + sub_dir + '.png'\n",
    "    mask_img = Image.open(mask_img_dir)\n",
    "    mask_img = mask_preprocess(mask_img).numpy()\n",
    "    \n",
    "    ppnet.eval()\n",
    "    n_prototypes = ppnet.module.num_prototypes\n",
    "    num_per_class = n_prototypes // 200\n",
    "    prototype_shape = ppnet.module.prototype_shape\n",
    "\n",
    "    test_img = test_img.unsqueeze(0).cuda()\n",
    "    _, proto_acts = ppnet.module.push_forward(test_img)\n",
    "    proto_dist = proto_acts.detach().cpu().numpy()\n",
    "\n",
    "    local_img_overlap = 0\n",
    "    global_img_overlap = 0\n",
    "    \n",
    "    class_identity = test_dataset.imgs[i][1]\n",
    "    for j in range(num_per_class):\n",
    "        act_pattern = np.log((proto_dist[0][class_identity * num_per_class + j] + 1)/(proto_dist[0][class_identity * num_per_class + j] + ppnet.module.epsilon))\n",
    "        upsampled_act_pattern = cv2.resize(act_pattern, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
    "        th = np.percentile(upsampled_act_pattern, percentile_threshold)\n",
    "        upsampled_act_pattern = (upsampled_act_pattern > th) * upsampled_act_pattern\n",
    "\n",
    "        prototype_overlap = np.sum(np.multiply(mask_img, upsampled_act_pattern)) / np.sum(upsampled_act_pattern)\n",
    "        local_img_overlap += prototype_overlap\n",
    "        \n",
    "    local_img_overlap /= num_per_class\n",
    "    total_local_overlap += local_img_overlap\n",
    "    \n",
    "    #global precision  \n",
    "    cls_tokens, _ = ppnet.module.prototype_distances(test_img)\n",
    "    global_activations, _ = ppnet.module.get_activations(cls_tokens, ppnet.module.prototype_vectors_global)\n",
    "    global_activations = global_activations.detach().cpu().numpy()\n",
    "    global_activation_pattern = global_activations[0].reshape(img_size, img_size)\n",
    "    global_overlap = np.sum(np.multiply(mask_img, global_activation_pattern)) / np.sum(global_activation_pattern)\n",
    "    total_global_overlap += global_overlap\n",
    "    \n",
    "avg_local_overlap = total_local_overlap / num_imgs\n",
    "avg_global_overlap = total_global_overlap / num_imgs\n",
    "\n",
    "print(\"Average Local Overlap: \", avg_local_overlap)\n",
    "print(\"Average Global Overlap: \", avg_global_overlap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c616a06-d379-4eb5-bbef-129f11b94d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5794 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'cls_token_attn' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m protoL_rf_info \u001b[38;5;241m=\u001b[39m ppnet\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mproto_layer_rf_info\n\u001b[1;32m     25\u001b[0m test_img \u001b[38;5;241m=\u001b[39m test_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 26\u001b[0m protoL_input_torch, proto_dist_torch \u001b[38;5;241m=\u001b[39m \u001b[43mppnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m proto_dist \u001b[38;5;241m=\u001b[39m proto_dist_torch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     29\u001b[0m img_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:340\u001b[0m, in \u001b[0;36mPPNet.push_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m'''this method is needed for the pushing operation'''\u001b[39;00m\n\u001b[1;32m    339\u001b[0m reserve_layer_nums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreserve_layer_nums\n\u001b[0;32m--> 340\u001b[0m (cls_tokens, img_tokens), (token_attn, cls_token_attn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprototype_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m global_activations, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_activations(cls_tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_vectors_global)\n\u001b[1;32m    342\u001b[0m local_activations, (distances, proto_acts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_activations(img_tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_vectors)\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:225\u001b[0m, in \u001b[0;36mPPNet.prototype_distances\u001b[0;34m(self, x, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mx is the raw input\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_global:\n\u001b[0;32m--> 225\u001b[0m     (cls_tokens, img_tokens), auxi_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (cls_tokens, img_tokens), auxi_item\n",
      "File \u001b[0;32m~/ProtoPNet/protopformer.py:155\u001b[0m, in \u001b[0;36mPPNet.conv_features\u001b[0;34m(self, x, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    152\u001b[0m fea_size, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x_embed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)), x_embed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    154\u001b[0m token_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m x, (cls_token_attn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_feature_mask_train_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_layer_nums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m final_reserve_num \u001b[38;5;241m=\u001b[39m reserve_layer_nums[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m final_reserve_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(cls_token_attn, k\u001b[38;5;241m=\u001b[39mfinal_reserve_num, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# (B, final_reserve_num)\u001b[39;00m\n",
      "File \u001b[0;32m~/ProtoPNet/tools/cait_models_attn.py:346\u001b[0m, in \u001b[0;36mMyCait.forward_feature_mask_train_direct\u001b[0;34m(self, cls_embed, x_embed, token_attn, reserve_layer_nums)\u001b[0m\n\u001b[1;32m    343\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    345\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, (\u001b[43mcls_token_attn\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'cls_token_attn' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "bad_img_idx = [193, 1764, 2472, 3082]\n",
    "#bad_img_idx = []\n",
    "percentile_threshold = 95\n",
    "#total_overlap = 0\n",
    "num_imgs = len(test_dataset.imgs)\n",
    "\n",
    "#GZ\n",
    "total_local_overlap = 0 \n",
    "total_global_overlap = 0 \n",
    "for i in tqdm(range(num_imgs)):\n",
    "    if i in bad_img_idx:\n",
    "        continue\n",
    "    test_img_dir = test_dataset.imgs[i][0]\n",
    "    sub_dir = test_img_dir[44:-4]\n",
    "    test_img = Image.open(test_img_dir)\n",
    "        \n",
    "    test_img = img_preprocess(test_img)\n",
    "    mask_img_dir = mask_dir + sub_dir + '.png'\n",
    "    mask_img = Image.open(mask_img_dir)\n",
    "    mask_img = mask_preprocess(mask_img).numpy()\n",
    "    \n",
    "    ppnet.eval()\n",
    "    #extract local prototypes? \n",
    "    n_prototypes = ppnet.module.num_prototypes\n",
    "    num_per_class = n_prototypes // 200\n",
    "    prototype_shape = ppnet.module.prototype_shape\n",
    "    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "    protoL_rf_info = ppnet.module.proto_layer_rf_info\n",
    "\n",
    "    test_img = test_img.unsqueeze(0).cuda()\n",
    "    protoL_input_torch, proto_dist_torch = ppnet.module.push_forward(test_img)\n",
    "    proto_dist = proto_dist_torch.detach().cpu().numpy()\n",
    "    \n",
    "    #img_overlap = 0\n",
    "    #GZ \n",
    "    local_img_overlap = 0 \n",
    "    global_activations, _ = ppnet.module.get_activations(cls_tokens, ppnet.module.prototype_vectors_global)\n",
    "\n",
    "    class_identity = test_dataset.imgs[i][1]\n",
    "    for j in range(num_per_class):\n",
    "        act_pattern = np.log((proto_dist[0][class_identity * num_per_class + j] + 1)/(proto_dist[0][class_identity * num_per_class + j] + ppnet.module.epsilon))\n",
    "        upsampled_act_pattern = cv2.resize(act_pattern, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
    "        th = np.percentile(upsampled_act_pattern, percentile_threshold)\n",
    "        upsampled_act_pattern = (upsampled_act_pattern > th) * upsampled_act_pattern\n",
    "        \n",
    "        prototype_overlap = np.sum(np.multiply(mask_img, upsampled_act_pattern)) / np.sum(upsampled_act_pattern)\n",
    "        #GZ\n",
    "        local_img_overlap += prototype_overlap \n",
    "    \n",
    "    #GZ \n",
    "    local_img_overlap = local_img_overlap / num_per_class\n",
    "    total_local_overlap += local_img_overlap \n",
    "    \n",
    "    total_overlap += img_overlap \n",
    "    \n",
    "print(\"Final score: \", total_overlap / num_imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "512a36b7-aa41-4ff4-96a8-b062ab0f4e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_overlap / 5794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "572933e8-d58e-421c-acdc-d65fda791fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_act_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db4efe8-a413-48e8-8c40-e986d428ec76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask0[100][150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e330a7-9e81-4a8b-b78b-40395422f43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
