{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fc4916-c7e1-4989-a8d6-7b052156a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import heapq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from receptive_field import compute_rf_prototype\n",
    "from helpers import makedir, find_high_activation_crop\n",
    "import shutil\n",
    "\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from helpers import makedir\n",
    "import model\n",
    "import push\n",
    "import prune\n",
    "import train_and_test as tnt\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function\n",
    "\n",
    "from bounding_box_metrics import bounding_box_overlap\n",
    "from find_nearest import find_k_nearest_patches_to_prototypes, imsave_with_bbox, ImagePatch, ImagePatchInfo\n",
    "\n",
    "from settings import train_dir, test_dir, train_push_dir, train_batch_size, test_batch_size, train_push_batch_size\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, prototype_activation_function, add_on_layers_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a19d46-b3df-4c90-a7c0-81952c193e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppnet = torch.load(r'/scratch/users/jiaxun1218/saved_models/vgg19_10/r1_0.7380.pth')\n",
    "#ppnet_multi = ppnet.cuda()\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2727883c-c8c1-4484-b832-6176d28295b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_push_dir = './stanford_cars/car_data/car_data/train'\n",
    "#test_dir = './stanford_cars/car_data/car_data/test'\n",
    "#train_dir = './stanford_cars/car_data/car_data/train_augmented'\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        train_push_dir,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accd01e8-15ac-4b2d-bddd-c0b2af642e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 5995\n",
       "    Root location: /scratch/users/jiaxun1218/data/train_cropped/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81119f1-fd3c-4566-a23c-3acbf419c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find nearest patches\n",
      "1.0\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Floating point image RGB values must be in the 0..1 range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfind_k_nearest_patches_to_prototypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_push_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# pytorch dataloader (must be unnormalized in [0,1])\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mppnet_multi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# pytorch network with prototype_vectors\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mpreprocess_input_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# normalize if needed\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfull_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# save all the images\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mroot_dir_for_saving_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./icml_figures/R1_vgg_bird/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mprototype_activation_function_in_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ProtoPNet/find_nearest.py:210\u001b[0m, in \u001b[0;36mfind_k_nearest_patches_to_prototypes\u001b[0;34m(dataloader, prototype_network_parallel, k, preprocess_input_function, full_save, root_dir_for_saving_images, log, prototype_activation_function_in_numpy, heatmap_ratio)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m#np.save(os.path.join(dir_for_saving_images,\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#                     'nearest-' + str(i+1) + '_original_with_heatmap.npy'),\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#        overlayed_original_img)\u001b[39;00m\n\u001b[1;32m    205\u001b[0m plt\u001b[38;5;241m.\u001b[39mimsave(fname\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_for_saving_images,\n\u001b[1;32m    206\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_original_with_heatmap.png\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    207\u001b[0m            arr\u001b[38;5;241m=\u001b[39moverlayed_original_img,\n\u001b[1;32m    208\u001b[0m            vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    209\u001b[0m            vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_for_saving_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_original.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m           \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m           \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m           \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# if different from original image, save the patch (i.e. receptive field)\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m#if patch.patch.shape[0] != img_size or patch.patch.shape[1] != img_size:\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#    np.save(os.path.join(dir_for_saving_images,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# save the highly activated patch    \u001b[39;00m\n\u001b[1;32m    236\u001b[0m high_act_patch_indices \u001b[38;5;241m=\u001b[39m find_high_activation_crop(upsampled_act_pattern)\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:2128\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave)\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimsave\u001b[39m(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/matplotlib/image.py:1630\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     sm \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mScalarMappable(cmap\u001b[38;5;241m=\u001b[39mcmap)\n\u001b[1;32m   1629\u001b[0m     sm\u001b[38;5;241m.\u001b[39mset_clim(vmin, vmax)\n\u001b[0;32m-> 1630\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1632\u001b[0m     pil_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/matplotlib/cm.py:493\u001b[0m, in \u001b[0;36mScalarMappable.to_rgba\u001b[0;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;129;01mand\u001b[39;00m (xx\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m xx\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloating point image RGB values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    494\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be in the 0..1 range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m    496\u001b[0m         xx \u001b[38;5;241m=\u001b[39m (xx \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31mValueError\u001b[0m: Floating point image RGB values must be in the 0..1 range."
     ]
    }
   ],
   "source": [
    "find_k_nearest_patches_to_prototypes(train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "                                         ppnet_multi, # pytorch network with prototype_vectors\n",
    "                                         k=1,\n",
    "                                         preprocess_input_function=None, # normalize if needed\n",
    "                                         full_save=True, # save all the images\n",
    "                                         root_dir_for_saving_images='./icml_figures/R1_vgg_bird/',\n",
    "                                         log=print,\n",
    "                                         prototype_activation_function_in_numpy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb454d-5792-437b-b48c-abe4a4be41de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
